{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "def03a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import colorsys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "403b8bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "\n",
    "# Path to directories\n",
    "IMGS_DIR = Path(\"images\")\n",
    "OUTPUT_DIR = Path(\"output\")\n",
    "\n",
    "# Grid shape for coverage calculation\n",
    "GRID_SHAPE = (3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1262f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image paths\n",
    "imgs_paths: list[Path] = []\n",
    "for file in Path(IMGS_DIR).iterdir():\n",
    "    if file.is_file() and file.suffix.lower() in {\".jpg\", \".png\", \".jpeg\"}:\n",
    "        imgs_paths.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8f52a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distinct_colors(amount: int) -> list[tuple[int, int, int]]:\n",
    "    \"\"\"\n",
    "    Generates a list of unique and distinct colors.\n",
    "    Each color is represented as an RGB tuple.\n",
    "    \"\"\"\n",
    "    colors = []\n",
    "    for i in range(amount):\n",
    "        # Evenly distribute hues in the HSV color space\n",
    "        hue = i / amount\n",
    "        saturation = 1.0  # Full saturation for vibrant colors\n",
    "        value = 1.0  # Full brightness\n",
    "        # Convert HSV to RGB and scale to 0-255\n",
    "        rgb = colorsys.hsv_to_rgb(hue, saturation, value)\n",
    "        rgb_scaled = tuple(int(c * 255) for c in rgb)\n",
    "        colors.append(rgb_scaled)\n",
    "\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55fc571d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(image: np.ndarray) -> None:\n",
    "    # Reset the figure\n",
    "    plt.clf()\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def save_image(image: np.ndarray, path: Path) -> None:\n",
    "    cv2.imwrite(str(path), image)\n",
    "    print(f\"Saved image to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9c51e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_images_orb(reference: np.ndarray, target: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Aligns img_to_align to base_img using ORB feature matching.\n",
    "    Returns the aligned image.\n",
    "    \"\"\"\n",
    "\n",
    "    # Detect ORB features and compute descriptors.\n",
    "    orb = cv2.ORB_create(5000)\n",
    "    keypoints1, descriptors1 = orb.detectAndCompute(reference, None)\n",
    "    keypoints2, descriptors2 = orb.detectAndCompute(target, None)\n",
    "\n",
    "    # Check if descriptors were found\n",
    "    if descriptors1 is None or descriptors2 is None:\n",
    "        raise ValueError(\n",
    "            f\"No keypoints found in image #{1 if descriptors1 is None else 2}.\"\n",
    "        )\n",
    "\n",
    "    # Match features.\n",
    "    matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = matcher.match(descriptors1, descriptors2)\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # Ensure there are enough matches\n",
    "    if len(matches) < 4:\n",
    "        raise ValueError(\"Not enough matches found to compute homography.\")\n",
    "\n",
    "    # Extract matched points.\n",
    "    pts1 = np.float32([keypoints1[m.queryIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "    pts2 = np.float32([keypoints2[m.trainIdx].pt for m in matches]).reshape(-1, 1, 2)\n",
    "\n",
    "    # Compute homography.\n",
    "    H, _ = cv2.findHomography(pts2, pts1, cv2.RANSAC)\n",
    "    aligned_img = cv2.warpPerspective(\n",
    "        target, H, (reference.shape[1], reference.shape[0])\n",
    "    )\n",
    "    return aligned_img\n",
    "\n",
    "\n",
    "def align_images_ecc(reference: np.ndarray, target: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Aligns img_to_align to base_img using ECC (Enhanced Correlation Coefficient).\n",
    "    Returns the aligned image.\n",
    "    \"\"\"\n",
    "    # Convert images to grayscale\n",
    "    gray_ref = cv2.cvtColor(reference, cv2.COLOR_BGR2GRAY)\n",
    "    gray_target = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Define the number of iterations and termination criteria\n",
    "    number_of_iterations = 5000\n",
    "    termination_eps = 1e-10\n",
    "    criteria = (\n",
    "        cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT,\n",
    "        number_of_iterations,\n",
    "        termination_eps,\n",
    "    )\n",
    "\n",
    "    # Define the motion model (translation + rotation)\n",
    "    warp_mode = cv2.MOTION_EUCLIDEAN\n",
    "\n",
    "    # Initialize the warp matrix\n",
    "    warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "\n",
    "    # Apply ECC algorithm to find the optimal warp matrix\n",
    "    cc, warp_matrix = cv2.findTransformECC(\n",
    "        gray_ref, gray_target, warp_matrix, warp_mode, criteria\n",
    "    )\n",
    "\n",
    "    # Apply the warp matrix to align the target image with the reference image\n",
    "    aligned_img = cv2.warpAffine(\n",
    "        target,\n",
    "        warp_matrix,\n",
    "        (reference.shape[1], reference.shape[0]),\n",
    "        flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP,\n",
    "    )\n",
    "    return aligned_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45364a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning image #2 to the first image...\n"
     ]
    }
   ],
   "source": [
    "def normalize_images(img_paths: list[Path]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Takes a set of images and calculates a \"normalized\" image.\n",
    "    \"\"\"\n",
    "    assert len(img_paths) > 1, \"At least two images are required for normalization.\"\n",
    "    images = []\n",
    "    for img_path in img_paths:\n",
    "        img = cv2.imread(str(img_path))\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not read image {img_path}.\")\n",
    "        # print(f\"Read image {img_path} with shape {img.shape}.\")\n",
    "        images.append(img)\n",
    "\n",
    "    assert all(img.shape == images[0].shape for img in images), (\n",
    "        \"All images must have the same resolution.\"\n",
    "    )\n",
    "\n",
    "    # Convert images to float32 for better precision in calculations.\n",
    "    images_float = [img.astype(np.float32) for img in images]\n",
    "\n",
    "    # Align all images to the first image\n",
    "    aligned_images = [images_float[0]]\n",
    "    for i, img in enumerate(images_float[1:]):\n",
    "        try:\n",
    "            print(f\"Aligning image #{i + 2} to the first image...\")\n",
    "            aligned_img = align_images_ecc(images_float[0], img)\n",
    "            aligned_images.append(aligned_img)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in alignment of image #{i + 2}: {e}\")\n",
    "            return None\n",
    "    aligned_images = np.array(aligned_images)\n",
    "\n",
    "    # Calculate the mean across all aligned images.\n",
    "    mean_image = np.mean(aligned_images, axis=0).astype(np.uint8)\n",
    "    display_image(mean_image)\n",
    "    save_image(mean_image, OUTPUT_DIR / \"normalized_image.png\")\n",
    "\n",
    "    return mean_image\n",
    "\n",
    "\n",
    "image_paths = [\n",
    "    IMGS_DIR / \"Al_10D_0b.jpg\",\n",
    "    IMGS_DIR / \"Al_10D_1.jpg\",\n",
    "    IMGS_DIR / \"Al_10D_2.jpg\",\n",
    "    IMGS_DIR / \"Al_10D_3.jpg\",\n",
    "    IMGS_DIR / \"Al_10D_4.jpg\",\n",
    "]\n",
    "_ = normalize_images(image_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce46809b",
   "metadata": {},
   "source": [
    "Timed out after >22m..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
